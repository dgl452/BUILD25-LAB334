{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Dataset from Azure Search Index using Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to generate a synthetic dataset of queries and responses using your Azure Search index with the Simulator tool. The generated dataset can be useful for:\n",
    "\n",
    "- Testing and evaluating RAG workflows\n",
    "- Fine-tuning prompts\n",
    "- Benchmarking search capabilities\n",
    "- Creating synthetic training data\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- Azure OpenAI Service access\n",
    "- Azure AI Search service with an indexed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment variables\n",
    "\n",
    "The following environment variables must be set before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Check for required environment variables\n",
    "assert os.environ.get(\"AZURE_OPENAI_API_KEY\") is not None, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_ENDPOINT\") is not None, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_API_VERSION\") is not None, \"Please set the AZURE_OPENAI_API_VERSION environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\") is not None, \"Please set the AZURE_OPENAI_DEPLOYMENT environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_ENDPOINT\") is not None, \"Please set the AZURE_SEARCH_ENDPOINT environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_API_KEY\") is not None, \"Please set the AZURE_SEARCH_API_KEY environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_INDEX_NAME\") is not None, \"Please set the AZURE_SEARCH_INDEX_NAME environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up search variables for later use\n",
    "search_endpoint = os.environ.get(\"AZURE_SEARCH_ENDPOINT\")\n",
    "index_name = os.environ.get(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "api_key = os.environ.get(\"AZURE_SEARCH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Simulator\n",
    "\n",
    "### 2.1 Configure Azure OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'azure_endpoint': 'https://aoai-51324400.openai.azure.com/', 'azure_deployment': 'gpt-4o-mini', 'api_key': '55b32d2e39584a7f9a17fa750261ffb7', 'api_version': '2025-01-01-preview'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "\n",
    "# Configure the model for the simulator\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create simulator instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class Simulator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation.simulator import Simulator\n",
    "\n",
    "simulator = Simulator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Connect to Search Index\n",
    "\n",
    "### 3.1 Create a function to retrieve data from the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def generate_text_from_index(search_term: str) -> str:\n",
    "    # Create the search request\n",
    "    url = f\"{search_endpoint}/indexes/{index_name}/docs/search?api-version=2023-11-01\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "    search_query = {\"search\": search_term, \"top\": 10}\n",
    "    \n",
    "    # Send the request\n",
    "    response = requests.post(url=url, headers=headers, json=search_query)\n",
    "        \n",
    "    # Check for errors\n",
    "    # Extract text from response\n",
    "    text = \"\"\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        for result in results[\"value\"]:\n",
    "            # Change this field based on your index schema\n",
    "            if \"content\" in result:\n",
    "                text += result[\"content\"] + \" \"\n",
    "    \n",
    "    # Limit text length to prevent token limit issues\n",
    "    return text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test the search functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text length: 500 characters\n",
      "\n",
      "Sample of retrieved text:\n",
      "Introducing the TrekReady Hiking Boots - stepping up your hiking game, one footprint at a time! Crafted from leather, these stylistic Trailmates are made to last. TrekReady infuses durability with its reinforced stitching and toe protection, making sure your journey is never stopped short. Comfort? ...\n"
     ]
    }
   ],
   "source": [
    "# Choose a search term relevant to your data\n",
    "search_term = \"Hiking Boots\"\n",
    "text = generate_text_from_index(search_term)\n",
    "print(f\"Generated text length: {len(text)} characters\")\n",
    "print(\"\\nSample of retrieved text:\")\n",
    "print(text[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Application Callback\n",
    "\n",
    "Define the callback functions that the simulator will use to interact with your index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "async def callback(\n",
    "    messages: Dict,\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict:\n",
    "    # Get the latest message\n",
    "    messages_list = messages[\"messages\"]\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "\n",
    "    deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "    endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    \n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    # Generate text from the index\n",
    "    context = generate_text_from_index(query)\n",
    "    \n",
    "    # Call the OpenAI API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": context,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    # Extract and return the response\n",
    "    response = completion.choices[0].message.content\n",
    "    \n",
    "    # Format the response\n",
    "    formatted_response = {\n",
    "        \"content\": response,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": context,\n",
    "    }\n",
    "    \n",
    "    # Add the response to messages\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Dataset\n",
    "\n",
    "### 5.1 Define tasks and run the simulator\n",
    "- Simulator uses text retreived from index to generate queries\n",
    "- Simulator uses these queries to get response by calling `target` callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.91s/message]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Run the simulator\n",
    "outputs = await simulator(\n",
    "    target=callback,\n",
    "    text=text,\n",
    "    num_queries=4,         # Number of query-response pairs to generate\n",
    "    max_conversation_turns=1,  # Number of conversation turns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Save the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to /workspaces/BUILD25-LAB334/labs/05-simulate-datasets.results.json\n"
     ]
    }
   ],
   "source": [
    "# Save the outputs to a file\n",
    "output_file = Path(\"05-simulate-datasets.results.json\")\n",
    "with output_file.open(\"a\") as f:\n",
    "    for output in outputs:\n",
    "        f.write(output.to_eval_qr_json_lines())\n",
    "    \n",
    "print(f\"Dataset saved to {output_file.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Review the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the TrekReady Hiking Boots made from?</td>\n",
       "      <td>The TrekReady Hiking Boots are crafted from le...</td>\n",
       "      <td>Introducing the TrekReady Hiking Boots - stepp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What feature ensures the TrekReady Hiking Boot...</td>\n",
       "      <td>The durability of the TrekReady Hiking Boots i...</td>\n",
       "      <td>Introducing the TrekReady Hiking Boots - stepp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What type of materials do the TrekReady Hiking...</td>\n",
       "      <td>The TrekReady Hiking Boots use breathable mate...</td>\n",
       "      <td>Introducing the TrekReady Hiking Boots - stepp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What design aspect contributes to the lightwei...</td>\n",
       "      <td>The lightweight nature of the TrekReady Hiking...</td>\n",
       "      <td>Introducing the TrekReady Hiking Boots - stepp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0     What are the TrekReady Hiking Boots made from?   \n",
       "1  What feature ensures the TrekReady Hiking Boot...   \n",
       "2  What type of materials do the TrekReady Hiking...   \n",
       "3  What design aspect contributes to the lightwei...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The TrekReady Hiking Boots are crafted from le...   \n",
       "1  The durability of the TrekReady Hiking Boots i...   \n",
       "2  The TrekReady Hiking Boots use breathable mate...   \n",
       "3  The lightweight nature of the TrekReady Hiking...   \n",
       "\n",
       "                                             context  \n",
       "0  Introducing the TrekReady Hiking Boots - stepp...  \n",
       "1  Introducing the TrekReady Hiking Boots - stepp...  \n",
       "2  Introducing the TrekReady Hiking Boots - stepp...  \n",
       "3  Introducing the TrekReady Hiking Boots - stepp...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_json(output_file, lines=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Now that you have generated a dataset, you can:\n",
    "\n",
    "1. Use it to evaluate retrieval quality\n",
    "2. Fine-tune prompts based on common query patterns\n",
    "3. Create test cases for your application\n",
    "4. Analyze the dataset to identify improvement opportunities\n",
    "\n",
    "To customize this notebook for your needs:\n",
    "\n",
    "- Modify the `search_term` to target specific content in your index\n",
    "- Update the `tasks` list to reflect your domain-specific use cases\n",
    "- Adjust the field names in `generate_text_from_index()` to match your index schema"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
