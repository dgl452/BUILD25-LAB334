{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Dataset from Azure Search Index using Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to generate a synthetic dataset of queries and responses using your Azure Search index with the Simulator tool. The generated dataset can be useful for:\n",
    "\n",
    "- Testing and evaluating RAG workflows\n",
    "- Fine-tuning prompts\n",
    "- Benchmarking search capabilities\n",
    "- Creating synthetic training data\n",
    "\n",
    "**Prerequisites:**\n",
    "\n",
    "- Azure OpenAI Service access\n",
    "- Azure AI Search service with an indexed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment variables\n",
    "\n",
    "The following environment variables must be set before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Check for required environment variables\n",
    "assert os.environ.get(\"AZURE_OPENAI_API_KEY\") is not None, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_ENDPOINT\") is not None, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_API_VERSION\") is not None, \"Please set the AZURE_OPENAI_API_VERSION environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\") is not None, \"Please set the AZURE_OPENAI_DEPLOYMENT_NAME environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_ENDPOINT\") is not None, \"Please set the AZURE_SEARCH_ENDPOINT environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_API_KEY\") is not None, \"Please set the AZURE_SEARCH_API_KEY environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_INDEX_NAME\") is not None, \"Please set the AZURE_SEARCH_INDEX_NAME environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up search variables for later use\n",
    "search_endpoint = os.environ.get(\"AZURE_SEARCH_ENDPOINT\")\n",
    "index_name = os.environ.get(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "api_key = os.environ.get(\"AZURE_SEARCH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize the Simulator\n",
    "\n",
    "### 2.1 Configure Azure OpenAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "\n",
    "# Configure the model for the simulator\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create simulator instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation.simulator import Simulator\n",
    "\n",
    "simulator = Simulator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Connect to Search Index\n",
    "\n",
    "### 3.1 Create a function to retrieve data from the search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "def generate_text_from_index(search_term: str) -> str:\n",
    "    # Create the search request\n",
    "    url = f\"{search_endpoint}/indexes/{index_name}/docs/search?api-version=2023-11-01\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "    search_query = {\"search\": search_term, \"top\": 10}\n",
    "    \n",
    "    # Send the request\n",
    "    response = requests.post(url=url, headers=headers, json=search_query)\n",
    "        \n",
    "    # Check for errors\n",
    "    # Extract text from response\n",
    "    text = \"\"\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        for result in results[\"value\"]:\n",
    "            # Change this field based on your index schema\n",
    "            if \"content\" in result:\n",
    "                text += result[\"content\"] + \" \"\n",
    "    \n",
    "    # Limit text length to prevent token limit issues\n",
    "    return text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test the search functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a search term relevant to your data\n",
    "search_term = \"Hiking Boots\"\n",
    "text = generate_text_from_index(search_term)\n",
    "print(f\"Generated text length: {len(text)} characters\")\n",
    "print(\"\\nSample of retrieved text:\")\n",
    "print(text[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Application Callback\n",
    "\n",
    "Define the callback functions that the simulator will use to interact with your index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "async def callback(\n",
    "    messages: Dict,\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict:\n",
    "    # Get the latest message\n",
    "    messages_list = messages[\"messages\"]\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "\n",
    "    deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "    endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    \n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    # Generate text from the index\n",
    "    context = generate_text_from_index(query)\n",
    "    \n",
    "    # Call the OpenAI API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": context,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    # Extract and return the response\n",
    "    response = completion.choices[0].message.content\n",
    "    \n",
    "    # Format the response\n",
    "    formatted_response = {\n",
    "        \"content\": response,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": context,\n",
    "    }\n",
    "    \n",
    "    # Add the response to messages\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Dataset\n",
    "\n",
    "### 5.1 Define tasks and run the simulator\n",
    "- Simulator uses text retreived from index to generate queries\n",
    "- Simulator uses these queries to get response by calling `target` callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Run the simulator\n",
    "outputs = await simulator(\n",
    "    target=callback,\n",
    "    text=text,\n",
    "    num_queries=4,         # Number of query-response pairs to generate\n",
    "    max_conversation_turns=1,  # Number of conversation turns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Save the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the outputs to a file\n",
    "output_file = Path(\"search_index_dataset.json\")\n",
    "with output_file.open(\"a\") as f:\n",
    "    for output in outputs:\n",
    "        f.write(output.to_eval_qr_json_lines())\n",
    "    \n",
    "print(f\"Dataset saved to {output_file.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Review the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_json(output_file, lines=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Now that you have generated a dataset, you can:\n",
    "\n",
    "1. Use it to evaluate retrieval quality\n",
    "2. Fine-tune prompts based on common query patterns\n",
    "3. Create test cases for your application\n",
    "4. Analyze the dataset to identify improvement opportunities\n",
    "\n",
    "To customize this notebook for your needs:\n",
    "\n",
    "- Modify the `search_term` to target specific content in your index\n",
    "- Update the `tasks` list to reflect your domain-specific use cases\n",
    "- Adjust the field names in `generate_text_from_index()` to match your index schema"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
