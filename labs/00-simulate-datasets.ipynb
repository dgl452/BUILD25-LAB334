{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate Dataset from Azure Search Index using Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to generate a synthetic dataset of queries and responses using your Azure Search index with the Simulator tool. The generated dataset can be useful for:\n",
    "\n",
    "- Testing and evaluating RAG workflows\n",
    "- Fine-tuning prompts\n",
    "- Benchmarking search capabilities\n",
    "- Creating synthetic training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Requisites\n",
    "\n",
    "1. An Azure OpenAI model deployment (chat completion)\n",
    "1. An Azure AI Search index (\"contoso-products\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- 1. Check that required environment variables are defined\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "assert os.environ.get(\"AZURE_OPENAI_API_KEY\") is not None, \"Please set the AZURE_OPENAI_API_KEY environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_ENDPOINT\") is not None, \"Please set the AZURE_OPENAI_ENDPOINT environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_API_VERSION\") is not None, \"Please set the AZURE_OPENAI_API_VERSION environment variable\"\n",
    "assert os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\") is not None, \"Please set the AZURE_OPENAI_DEPLOYMENT environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_ENDPOINT\") is not None, \"Please set the AZURE_SEARCH_ENDPOINT environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_API_KEY\") is not None, \"Please set the AZURE_SEARCH_API_KEY environment variable\"\n",
    "assert os.environ.get(\"AZURE_SEARCH_INDEX_NAME\") is not None, \"Please set the AZURE_SEARCH_INDEX_NAME environment variable\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ------- 2. Initialize the required variables to work with the Azure AI Search service\n",
    "search_endpoint = os.environ.get(\"AZURE_SEARCH_ENDPOINT\")\n",
    "index_name = os.environ.get(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "api_key = os.environ.get(\"AZURE_SEARCH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Initialize the Simulator\n",
    "\n",
    "### 2.1 Create a Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'azure_endpoint': 'https://aoai-51373678.openai.azure.com/', 'azure_deployment': 'gpt-4o-mini', 'api_key': 'eaaadc31147242c19e433416ed2df037', 'api_version': '2025-01-01-preview'}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    azure_deployment=os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    ")\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Instantiate Simulator with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation.simulator import Simulator\n",
    "\n",
    "simulator = Simulator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Connect to the Search Index\n",
    "\n",
    "### 3.1 Define function to retrieve search results for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def generate_text_from_index(search_term: str) -> str:\n",
    "\n",
    "    # Create the search request\n",
    "    url = f\"{search_endpoint}/indexes/{index_name}/docs/search?api-version=2023-11-01\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "    search_query = {\"search\": search_term, \"top\": 10}\n",
    "    \n",
    "    # Send the request\n",
    "    response = requests.post(url=url, headers=headers, json=search_query)\n",
    "        \n",
    "    # Check for errors\n",
    "    # Extract text from response\n",
    "    text = \"\"\n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        for result in results[\"value\"]:\n",
    "            # Change this field based on your index schema\n",
    "            if \"content\" in result:\n",
    "                text += result[\"content\"] + \" \"\n",
    "    \n",
    "    # Limit text length to prevent token limit issues\n",
    "    return text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Test the function works with a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text length: 500 characters\n",
      "\n",
      "Sample of retrieved text:\n",
      "CampBuddy's BaseCamp Folding Table is an adventurer's best friend. Lightweight yet powerful, the table is a testament to fun-meets-function and will elevate any outing to new heights. Crafted from resilient, rust-resistant aluminum, the table boasts a generously sized 48 x 24 inches tabletop, perfec...\n"
     ]
    }
   ],
   "source": [
    "# Choose a search term relevant to your data\n",
    "search_term = \"Dining Table\"\n",
    "text = generate_text_from_index(search_term)\n",
    "print(f\"Generated text length: {len(text)} characters\")\n",
    "print(\"\\nSample of retrieved text:\")\n",
    "print(text[:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Create Application Callback\n",
    "\n",
    "Define the callback functions that the simulator will use to interact with your index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "async def callback(\n",
    "    messages: Dict,\n",
    "    stream: bool = False,\n",
    "    session_state: Any = None,\n",
    "    context: Optional[Dict[str, Any]] = None,\n",
    ") -> dict:\n",
    "    # Get the latest message\n",
    "    messages_list = messages[\"messages\"]\n",
    "    latest_message = messages_list[-1]\n",
    "    query = latest_message[\"content\"]\n",
    "\n",
    "    deployment = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
    "    endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    \n",
    "    # Initialize Azure OpenAI client\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=endpoint,\n",
    "        api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    # Generate text from the index\n",
    "    context = generate_text_from_index(query)\n",
    "    \n",
    "    # Call the OpenAI API\n",
    "    completion = client.chat.completions.create(\n",
    "        model=deployment,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": context,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=800,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    \n",
    "    # Extract and return the response\n",
    "    response = completion.choices[0].message.content\n",
    "    \n",
    "    # Format the response\n",
    "    formatted_response = {\n",
    "        \"content\": response,\n",
    "        \"role\": \"assistant\",\n",
    "        \"context\": context,\n",
    "    }\n",
    "    \n",
    "    # Add the response to messages\n",
    "    messages[\"messages\"].append(formatted_response)\n",
    "    return {\"messages\": messages[\"messages\"], \"stream\": stream, \"session_state\": session_state, \"context\": context}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Generate & Save Dataset\n",
    "\n",
    "### 5.1 Define tasks and run the simulator\n",
    "- Simulator uses text retrieved from index to generate queries\n",
    "- Simulator uses these queries to get response by calling `target` callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/azure/ai/evaluation/simulator/_simulator.py:151: UserWarning: You have specified 'num_queries' > len('tasks') (4 > 0). All tasks will be used for generation and the remaining 4 lines will be simulated in task-free mode\n",
      "  warnings.warn(\n",
      "Generating: 100%|████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.90s/message]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Run the simulator\n",
    "outputs = await simulator(\n",
    "    target=callback,\n",
    "    text=text,\n",
    "    num_queries=4,         # Number of query-response pairs to generate\n",
    "    max_conversation_turns=1,  # Number of conversation turns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Save the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to /workspaces/BUILD25-LAB334/labs/00-simulate-datasets.results.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Save the outputs to a file\n",
    "output_file = Path(\"00-simulate-datasets.results.jsonl\")\n",
    "with output_file.open(\"a\") as f:\n",
    "    for output in outputs:\n",
    "        f.write(output.to_eval_qr_json_lines())\n",
    "    \n",
    "print(f\"Dataset saved to {output_file.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Review the generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the size of CampBuddy's BaseCamp Foldi...</td>\n",
       "      <td>The size of CampBuddy's BaseCamp Folding Table...</td>\n",
       "      <td>CampBuddy's BaseCamp Folding Table is an adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What material is CampBuddy's BaseCamp Folding ...</td>\n",
       "      <td>CampBuddy's BaseCamp Folding Table is made fro...</td>\n",
       "      <td>CampBuddy's BaseCamp Folding Table is an adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What feature of the CampBuddy's BaseCamp Foldi...</td>\n",
       "      <td>The adjustable legs of the CampBuddy's BaseCam...</td>\n",
       "      <td>CampBuddy's BaseCamp Folding Table is an adven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the primary purpose of CampBuddy's Bas...</td>\n",
       "      <td>The primary purpose of CampBuddy's BaseCamp Fo...</td>\n",
       "      <td>CampBuddy's BaseCamp Folding Table is an adven...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  What is the size of CampBuddy's BaseCamp Foldi...   \n",
       "1  What material is CampBuddy's BaseCamp Folding ...   \n",
       "2  What feature of the CampBuddy's BaseCamp Foldi...   \n",
       "3  What is the primary purpose of CampBuddy's Bas...   \n",
       "\n",
       "                                            response  \\\n",
       "0  The size of CampBuddy's BaseCamp Folding Table...   \n",
       "1  CampBuddy's BaseCamp Folding Table is made fro...   \n",
       "2  The adjustable legs of the CampBuddy's BaseCam...   \n",
       "3  The primary purpose of CampBuddy's BaseCamp Fo...   \n",
       "\n",
       "                                             context  \n",
       "0  CampBuddy's BaseCamp Folding Table is an adven...  \n",
       "1  CampBuddy's BaseCamp Folding Table is an adven...  \n",
       "2  CampBuddy's BaseCamp Folding Table is an adven...  \n",
       "3  CampBuddy's BaseCamp Folding Table is an adven...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.read_json(output_file, lines=True).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Review the saved dataset file\n",
    "\n",
    "- Open the `00-simulate-datasets.results.jsonl` file in your Visual Studio Code editor\n",
    "- You should see a list of generated {query-response-context} lines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Next Steps\n",
    "\n",
    "Now that you have generated a dataset, you can:\n",
    "\n",
    "1. Use it to evaluate retrieval quality\n",
    "2. Fine-tune prompts based on common query patterns\n",
    "3. Create test cases for your application\n",
    "4. Analyze the dataset to identify improvement opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Homework: Try It Out\n",
    "\n",
    "To customize this notebook for your needs:\n",
    "\n",
    "- Recreate the Azure AI Search index with your data and index name\n",
    "- Modify the `search_term` to target specific content in your index\n",
    "- Update the `tasks` list to reflect your domain-specific use cases\n",
    "- Adjust the field names in `generate_text_from_index()` to match your index schema"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "notebook_template.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
